{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obj(filename):\n",
    "    mesh = {\n",
    "        'vertices': [],\n",
    "        'faces': [],\n",
    "        'edges': []\n",
    "    }\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):\n",
    "                mesh['vertices'].append([float(v) for v in line.strip().split()[1:]])\n",
    "            elif line.startswith('f '):\n",
    "                face = [int(idx.split('/')[0]) - 1 for idx in line.strip().split()[1:]]\n",
    "                mesh['faces'].append(face)\n",
    "                mesh['edges'].append([face[0], face[1]])\n",
    "                mesh['edges'].append([face[1], face[2]])\n",
    "                mesh['edges'].append([face[2], face[0]])\n",
    "           \n",
    "    mesh['vertices'] = np.array(mesh['vertices'])\n",
    "    mesh['faces'] = np.array(mesh['faces'])\n",
    "    mesh['edges'] = np.array(mesh['edges']) \n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.layers.mesh_pool import MeshPool\n",
    "from models.layers.mesh_conv import MeshConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_args(norm_layer, nfeats_list):\n",
    "    if hasattr(norm_layer, '__name__') and norm_layer.__name__ == 'NoNorm':\n",
    "        norm_args = [{'fake': True} for f in nfeats_list]\n",
    "    elif norm_layer.func.__name__ == 'GroupNorm':\n",
    "        norm_args = [{'num_channels': f} for f in nfeats_list]\n",
    "    elif norm_layer.func.__name__ == 'BatchNorm':\n",
    "        norm_args = [{'num_features': f} for f in nfeats_list]\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_layer.func.__name__)\n",
    "    return norm_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshConvNet(nn.Module):\n",
    "    \"\"\"Network for learning a global shape descriptor (classification)\n",
    "    \"\"\"\n",
    "    def __init__(self, norm_layer, nf0, conv_res, nclasses, input_res, pool_res, fc_n,\n",
    "                 nresblocks=3):\n",
    "        super(MeshConvNet, self).__init__()\n",
    "        self.k = [nf0] + conv_res\n",
    "        self.res = [input_res] + pool_res\n",
    "        norm_args = get_norm_args(norm_layer, self.k[1:])\n",
    "\n",
    "        for i, ki in enumerate(self.k[:-1]):\n",
    "            setattr(self, 'conv{}'.format(i), MResConv(ki, self.k[i + 1], nresblocks))\n",
    "            setattr(self, 'norm{}'.format(i), norm_layer(**norm_args[i]))\n",
    "            setattr(self, 'pool{}'.format(i), MeshPool(self.res[i + 1]))\n",
    "\n",
    "\n",
    "        self.gp = torch.nn.AvgPool1d(self.res[-1])\n",
    "        self.fc1 = nn.Linear(self.k[-1], fc_n)\n",
    "        self.fc2 = nn.Linear(fc_n, nclasses)\n",
    "\n",
    "    def forward(self, x, mesh):\n",
    "\n",
    "        for i in range(len(self.k) - 1):\n",
    "            x = getattr(self, 'conv{}'.format(i))(x, mesh)\n",
    "            x = F.relu(getattr(self, 'norm{}'.format(i))(x))\n",
    "            x = getattr(self, 'pool{}'.format(i))(x, mesh)\n",
    "\n",
    "        x = self.gp(x)\n",
    "        x = x.view(-1, self.k[-1])\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MResConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, skips=1):\n",
    "        super(MResConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.skips = skips\n",
    "        self.conv0 = MeshConv(self.in_channels, self.out_channels, bias=False)\n",
    "        for i in range(self.skips):\n",
    "            setattr(self, 'bn{}'.format(i + 1), nn.BatchNorm2d(self.out_channels))\n",
    "            setattr(self, 'conv{}'.format(i + 1),\n",
    "                    MeshConv(self.out_channels, self.out_channels, bias=False))\n",
    "\n",
    "    def forward(self, x, mesh):\n",
    "        x = self.conv0(x, mesh)\n",
    "        x1 = x\n",
    "        for i in range(self.skips):\n",
    "            x = getattr(self, 'bn{}'.format(i + 1))(F.relu(x))\n",
    "            x = getattr(self, 'conv{}'.format(i + 1))(x, mesh)\n",
    "        x += x1\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU IDs: [0]\n",
      "Batch size: 8\n",
      "computing mean std from train data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[(0, 0), (0, -29250)] cannot contain negative values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fdbba4943dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Manually create dataset object using `opt`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Create DataLoader with all options specified in `opt`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/3DMesh-HumanPoseEstimation/MeshCNN/data/classification_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# modify for network later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/3DMesh-HumanPoseEstimation/MeshCNN/data/base_dataset.py\u001b[0m in \u001b[0;36mget_mean_std\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} of {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/3DMesh-HumanPoseEstimation/MeshCNN/data/classification_data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# get edge features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mninput_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge_features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/3DMesh-HumanPoseEstimation/MeshCNN/util/util.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(input_arr, target_length, val, dim)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseg_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeshes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/meshcnn/lib/python3.6/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0mnarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     allowedkwargs = {\n",
      "\u001b[0;32m~/miniconda3/envs/meshcnn/lib/python3.6/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_validate_lengths\u001b[0;34m(narray, number_elements)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s cannot contain negative values.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormshp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [(0, 0), (0, -29250)] cannot contain negative values."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data.classification_data import ClassificationData  # Custom dataset\n",
    "from data.base_dataset import collate_fn  # Custom collate function\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        # Define all the necessary options with default values\n",
    "        self.dataroot = \"datasets/human_class\"  # Dataset root directory\n",
    "        self.phase = \"train\"  # Phase (train/test)\n",
    "        self.batch_size = 8  # Batch size\n",
    "        self.ninput_edges = 750  # Number of input edges for mesh\n",
    "        self.num_threads = 4  # Number of workers for data loading\n",
    "        self.gpu_ids = [0]  # Use GPU (set to [] for CPU)\n",
    "        self.max_dataset_size = float('inf')  # Maximum dataset size\n",
    "        self.serial_batches = False  # Shuffle data (False means shuffle)\n",
    "        self.export_folder = None  # Folder for export results (if any)\n",
    "        self.save_latest_freq = 1000  # Frequency of saving model\n",
    "        self.print_freq = 100  # Frequency of printing log messages\n",
    "        self.epoch_count = 1  # Start counting from which epoch\n",
    "        self.niter = 50  # Number of iterations at base learning rate\n",
    "        self.niter_decay = 50  # Number of iterations with learning rate decay\n",
    "        self.save_epoch_freq = 10  # Frequency of saving model at each epoch\n",
    "        self.verbose_plot = False  # Verbose plotting (e.g. weight plots)\n",
    "        self.run_test_freq = 5  # Frequency to run tests\n",
    "        self.num_aug = 20  # Number of augmentations  \n",
    "\n",
    "# Initialize the Options object\n",
    "opt = Options()\n",
    "\n",
    "# Now we can access the options like opt.gpu_ids, opt.batch_size, etc.\n",
    "print(\"Using GPU IDs:\", opt.gpu_ids)\n",
    "print(\"Batch size:\", opt.batch_size)\n",
    "\n",
    "# Then use `opt` just like you would in the original code\n",
    "\n",
    "# Manually create dataset object using `opt`\n",
    "dataset = ClassificationData(opt)\n",
    "\n",
    "# Create DataLoader with all options specified in `opt`\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=not opt.serial_batches,\n",
    "    num_workers=opt.num_threads,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Example usage in training\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
