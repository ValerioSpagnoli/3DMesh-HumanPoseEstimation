{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesh_keypoints_extraction import KeypointPredictionNetwork, MeshData, train, test, custom_collate_fn, ChamferLoss, SumOfDistancesLoss, HungarianSumOfDistancesLoss\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'mesh_keypoints_extraction_dataset'\n",
    "meshes_dir = os.path.join(dataset_dir, 'meshes')\n",
    "keypoints_dir = os.path.join(dataset_dir, 'keypoints')\n",
    "model_save_dir = 'models/'\n",
    "\n",
    "num_edges = 750\n",
    "input_channels = 5\n",
    "num_keypoints = 12\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeshData(meshes_dir, keypoints_dir, device=device, num_edges=num_edges, normalize=True)\n",
    "train_set_size = int(0.8 * len(dataset))\n",
    "val_set_size = int(0.1 * len(dataset))\n",
    "test_set_size = len(dataset) - train_set_size - val_set_size\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, val_set_size, test_set_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_predictor = KeypointPredictionNetwork(input_channels=input_channels, num_keypoints=num_keypoints).to(device)\n",
    "keypoints_predictor.load_state_dict(torch.load(model_save_dir + 'keypoints_predictor.pth', weights_only=True))\n",
    "\n",
    "optimizer = optim.Adam(keypoints_predictor.parameters(), lr=learning_rate)\n",
    "\n",
    "chamfer_loss = ChamferLoss()\n",
    "sum_of_distances_loss = SumOfDistancesLoss()\n",
    "hungarian_sum_of_distances_loss = HungarianSumOfDistancesLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Training: 100%|██████████| 8/8 [01:38<00:00, 12.32s/it]\n",
      " - Validation: 100%|██████████| 1/1 [00:12<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Train Loss: 1.2037423104047775 - Valid Loss: 1.1974538564682007 - Learning Rate: 0.001\n",
      "Epoch 2/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Training:  50%|█████     | 4/8 [00:54<00:55, 13.77s/it]"
     ]
    }
   ],
   "source": [
    "train(keypoints_predictor, optimizer, hungarian_sum_of_distances_loss, scaler, scheduler, train_loader, valid_loader, num_epochs, device, model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_predictor_test = KeypointPredictionNetwork(input_channels=input_channels, num_keypoints=num_keypoints).to(device)\n",
    "keypoints_predictor_test.load_state_dict(torch.load(model_save_dir + 'keypoints_predictor.pth', weights_only=True))\n",
    "test(keypoints_predictor_test, test_loader, hungarian_sum_of_distances_loss, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh, edge_features, keypoints = train_set[140]\n",
    "keypoints = keypoints.cpu().detach().numpy()\n",
    "predicted_keypoints = keypoints_predictor(edge_features.unsqueeze(0).to(torch.float32).to(device)).squeeze().cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(scene=dict(aspectmode='data'))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Mesh3d(x=mesh.vertices[:, 0], y=mesh.vertices[:, 1], z=mesh.vertices[:, 2], i=mesh.faces[:, 0], j=mesh.faces[:, 1], k=mesh.faces[:, 2], color='lightgrey', opacity=0.5))\n",
    "\n",
    "for i, keypoint in enumerate(predicted_keypoints):\n",
    "    fig.add_trace(go.Scatter3d(x=[keypoint[0]], y=[keypoint[1]], z=[keypoint[2]], mode='markers', marker=dict(size=5, color='blue')))\n",
    "\n",
    "for i, keypoint in enumerate(keypoints):\n",
    "    fig.add_trace(go.Scatter3d(x=[keypoint[0]], y=[keypoint[1]], z=[keypoint[2]], mode='markers', marker=dict(size=3, color='red')))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
