{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from extract_edge_features_cuda import compute_edges_properties, batch_simple_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'datasets/simple_edge_features_2d_old'  # Change this to your actual dataset path\n",
    "save_dir = 'models/simple_edge_features/'\n",
    "input_features = 3\n",
    "num_edges = 512  # Predefined row length (number of rows to keep)\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = 'datasets/human'\n",
    "dataset_indices = {'bouncing': [], 'crane': [], 'handstand': [], 'jumping': [], 'march_1': [], 'march_2': [], 'samba': [], 'squat_1': [], 'squat_2': []}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_root):\n",
    "    if len(files) > 0:\n",
    "        class_name = root.split('/')[-1]\n",
    "        dataset_indices[class_name] = [os.path.join(root, file).split('_')[-1].split('.')[0] for file in files]\n",
    "\n",
    "train_indices = {}\n",
    "val_indices = {}\n",
    "test_indices = {}\n",
    "\n",
    "for class_name in dataset_indices.keys():\n",
    "    dataset_class_length = len(dataset_indices[class_name])\n",
    "    train_indices[class_name] = dataset_indices[class_name][:int(0.7 * dataset_class_length)]\n",
    "    val_indices[class_name] = dataset_indices[class_name][int(0.7 * dataset_class_length):int(0.85 * dataset_class_length)]\n",
    "    test_indices[class_name] =  dataset_indices[class_name][int(0.85 * dataset_class_length):]\n",
    "\n",
    "\n",
    "tot_number_of_train_samples = 0\n",
    "for class_name in train_indices.keys():\n",
    "    number_of_samples = len(train_indices[class_name])\n",
    "    tot_number_of_train_samples += number_of_samples\n",
    "    # print(f'number of samples in {class_name} train: {number_of_samples}')\n",
    "print(f'total number of train samples: {tot_number_of_train_samples}\\n')\n",
    "    \n",
    "tot_number_of_val_samples = 0\n",
    "for class_name in val_indices.keys():\n",
    "    number_of_samples = len(val_indices[class_name])\n",
    "    tot_number_of_val_samples += number_of_samples\n",
    "    # print(f'number of samples in {class_name} val: {number_of_samples}')\n",
    "print(f'total number of val samples: {tot_number_of_val_samples}\\n')\n",
    "\n",
    "tot_number_of_test_samples = 0\n",
    "for class_name in test_indices.keys():\n",
    "    number_of_samples = len(test_indices[class_name])\n",
    "    tot_number_of_test_samples += number_of_samples\n",
    "    # print(f'number of samples in {class_name} test: {number_of_samples}')\n",
    "print(f'total number of test samples: {tot_number_of_test_samples}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgesFeaturesDataset(Dataset):\n",
    "    def __init__(self, root_dir, indices, num_edges, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.indices = indices\n",
    "        self.num_edges = num_edges\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            class_name = class_dir.split('/')[-1]\n",
    "            class_indices = self.indices[class_name]\n",
    "            if os.path.isdir(class_dir):\n",
    "                files = [f for f in os.listdir(class_dir) if f.endswith('.pt')]\n",
    "                for file in files:\n",
    "                    file_index = file.split('_')[-1].split('.')[0]\n",
    "                    if file_index not in class_indices: \n",
    "                      continue\n",
    "                    path = os.path.join(class_dir, file)\n",
    "                    label = class_name\n",
    "                    self.samples.append((path, label))\n",
    "\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(sorted(set([s[1] for s in self.samples])))}\n",
    "        self.idx_to_class = {idx: cls_name for cls_name, idx in self.class_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        label_idx = self.class_to_idx[label]\n",
    "        label_tensor = torch.tensor(label_idx, dtype=torch.long)\n",
    "        edge_features_tensor = torch.load(path, weights_only=True)  # edge_features_Tensor shape is (N, 7)\n",
    "\n",
    "        if edge_features_tensor.shape[0] >= self.num_edges:\n",
    "            edge_features_tensor = edge_features_tensor[:self.num_edges, :]\n",
    "        else:\n",
    "            padding = torch.zeros((self.num_edges - edge_features_tensor.shape[0], edge_features_tensor.shape[1]))\n",
    "            edge_features_tensor = torch.cat((edge_features_tensor, padding), dim=0)\n",
    "\n",
    "        if self.transform:\n",
    "            edge_features_tensor = self.transform(edge_features_tensor)\n",
    "\n",
    "        edge_features_tensor = edge_features_tensor.clone().detach().float()\n",
    "\n",
    "        return edge_features_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshDataset(Dataset):\n",
    "    def __init__(self, root_dir, indices, num_edges, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.indices = indices\n",
    "        self.num_edges = num_edges\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        for class_name in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            class_name = class_dir.split('/')[-1]\n",
    "            class_indices = self.indices[class_name]\n",
    "            if os.path.isdir(class_dir):\n",
    "                files = [f for f in os.listdir(class_dir) if f.endswith('.obj')]\n",
    "                for file in files:\n",
    "                    file_index = file.split('_')[-1].split('.')[0]\n",
    "                    if file_index not in class_indices: continue\n",
    "                    path = os.path.join(class_dir, file)\n",
    "                    label = class_name\n",
    "                    self.samples.append((path, label))\n",
    "\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(sorted(set([s[1] for s in self.samples])))}\n",
    "        self.idx_to_class = {idx: cls_name for cls_name, idx in self.class_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        label_idx = self.class_to_idx[label]\n",
    "        label_tensor = torch.tensor(label_idx, dtype=torch.long)\n",
    "        \n",
    "        mesh = trimesh.load_mesh(path)\n",
    "        edge_properties = compute_edges_properties(mesh)\n",
    "        edge_features_tensor = batch_simple_edge_features(edge_properties, device=self.device)\n",
    "                \n",
    "        if edge_features_tensor.shape[0] >= self.num_edges:\n",
    "            edge_features_tensor = edge_features_tensor[:self.num_edges, :]\n",
    "        else:\n",
    "            padding = torch.zeros((self.num_edges - edge_features_tensor.shape[0], edge_features_tensor.shape[1]))\n",
    "            edge_features_tensor = torch.cat((edge_features_tensor, padding), dim=0)\n",
    "\n",
    "        if self.transform:\n",
    "            edge_features_tensor = self.transform(edge_features_tensor)\n",
    "\n",
    "        edge_features_tensor = edge_features_tensor.clone().detach().float()\n",
    "\n",
    "        return edge_features_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshEdgesCNN2D(nn.Module):\n",
    "    def __init__(self, num_classes, input_features):\n",
    "        super(MeshEdgesCNN2D, self).__init__()\n",
    "\n",
    "        # Define 2D convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_features, out_channels=8, kernel_size=(3, 3), padding=1)  # Input channels = 3\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "        # Define max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # Calculate the size of the flattened layer based on pooling operations\n",
    "        self.fc1 = nn.Linear(32 * 128 * 1, 128)  # Adjust size after pooling\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 3, 512, 7)\n",
    "        # Ensure the shape is (batch_size, C, H, W) i.e., (batch_size, 3, 512, 7)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        \n",
    "        \n",
    "        # Apply convolution layers with ReLU activation and pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # (batch_size, 8, 256, 3)\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # (batch_size, 16, 128, 1)\n",
    "        x = self.relu(self.conv3(x))              # (batch_size, 32, 128, 1) - no pooling to preserve size\n",
    "\n",
    "        # Flatten the output to feed into the fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 32 * 128 * 1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EdgesFeaturesDataset(root_dir, train_indices, num_edges)\n",
    "val_dataset = EdgesFeaturesDataset(root_dir, val_indices, num_edges)\n",
    "test_dataset = EdgesFeaturesDataset(root_dir, test_indices, num_edges)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MeshEdgesCNN2D(num_classes=num_classes, input_features=input_features).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "      inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_loss += loss.item()\n",
    "\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "        f'Train Loss: {running_loss/len(train_loader):.4f}, '\n",
    "        f'Validation Loss: {val_loss/len(val_loader):.4f}, '\n",
    "        f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "  \n",
    "  torch.save(model.state_dict(), save_dir + f'checkpoints/simple_edge_features_{epoch}.pth')\n",
    "  \n",
    "torch.save(model.state_dict(), save_dir + 'simple_edge_features.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = MeshEdgesCNN2D(num_classes=num_classes, input_features=input_features).to(device)\n",
    "test_model.load_state_dict(torch.load(save_dir+'simple_edge_features.pth', weights_only=True))\n",
    "test_model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(torch.float32).to(device)\n",
    "        labels = labels.to(torch.long).to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')  # Normalize over the true labels\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=test_dataset.idx_to_class.values(), yticklabels=test_dataset.idx_to_class.values())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Compute Precision, Recall and F1-Score\n",
    "precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "for i, cls_name in test_dataset.idx_to_class.items():\n",
    "    print(f'{cls_name}: Precision={precision[i]:.2f}, Recall={recall[i]:.2f}, F1-Score={f1_score[i]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_mesh = MeshDataset(dataset_root, test_indices, num_edges)\n",
    "test_loader_mesh = DataLoader(test_dataset_mesh, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_model = MeshEdgesCNN2D(num_classes=num_classes, input_features=input_features).to(device)\n",
    "test_model.load_state_dict(torch.load(save_dir+'simple_edge_features.pth', weights_only=True))\n",
    "test_model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for data, labels in tqdm(test_loader_mesh, desc=\"Testing\"):\n",
    "        data = data.to(torch.float32).to(device)\n",
    "        labels = labels.to(torch.long).to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')  # Normalize over the true labels\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=test_dataset.idx_to_class.values(), yticklabels=test_dataset.idx_to_class.values())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Compute Precision, Recall and F1-Score\n",
    "precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "for i, cls_name in test_dataset.idx_to_class.items():\n",
    "    print(f'{cls_name}: Precision={precision[i]:.2f}, Recall={recall[i]:.2f}, F1-Score={f1_score[i]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
